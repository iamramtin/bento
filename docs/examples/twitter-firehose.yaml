input:
  http_client:
    url: https://gnip-stream.twitter.com/stream/firehose/accounts/foo/publishers/twitter/prod.json?partition=1
    verb: GET
    content_type: application/json
    basic_auth:
      enabled: true
      password: "" # TODO
      username: "" # TODO
    stream:
      enabled: true
      max_buffer: 10_000_000 # 10MB - The max supported length of a single line
  processors:
  # Filter out keep alives (empty message)
  - bounds_check:
      min_part_size: 2

buffer:
  memory:
    limit: 500_000_000

pipeline:
  threads: 16 # Determines the max number of concurrent calls to dedupe cache
  processors:
  # Filter out non-json objects and error messages
  - filter:
      jmespath:
        query: "keys(@) | length(@) > `0` && !contains(@, 'error')"
  - dedupe:
      cache: dedupe
      drop_on_err: false # Prefer occasional duplicates over lost messages
      key: "${!json_field:id_str}" # Dedupe based on 'id_str' field of tweets
      hash: none

output:
  kafka:
    addresses:
    - localhost:9092 # TODO
    client_id: benthos_firehose_bridge
    topic: twitter_firehose
    max_msg_bytes: 10_000_000 # 10MB - The max supported message size

resources:
  caches:
    dedupe:
      memcached:
        addresses:
        - localhost:11211 # TODO
        ttl: 604_800 # Keep Twitter IDs cached for a week
