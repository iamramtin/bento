# This config assumes that fewer than 100 tweets will be scraped within each 3m
# interval. If this is not the case then you can either increase the interval in
# order to trigger more frequent scrapes.
#
# Alternatively, you could use a `while` processor in order to continue pulling
# more tweets whenever the response is saturated (100 tweets per request).
# However, I'm not very popular so 100 tweets every 3 minutes seems enough.
input:
  generate:
    interval: '0 */3 * * * *'
    mapping: root = ""
  processors:
    - resource: tweets_to_discord
    - catch:
      - log:
          message: "Error: ${! error() }"
    - bloblang: 'root = deleted()'

cache_resources:
  - label: request_tracking
    file:
      directory: /cache

processor_resources:
  # Logic to build a Twitter search URL by looking up a cache of the latest
  # tweet ID seen.
  - label: next_tweet_search_url
    for_each:
      - cache:
          resource: request_tracking
          operator: get
          key: last_tweet_id

      - catch: [] # Don't care if the cache is empty

      - bloblang: |
          let search = "(benthos.dev OR jeffail) OR (\"https://github.com/Jeffail/benthos\" -from:GolangRepos) OR (from:benthosdev) OR (@benthosdev)"
          let url_base = "https://api.twitter.com/2/tweets/search/recent"
          let query_base = "?tweet.fields=author_id&max_results=100&query=" + $search.escape_url_query()
          let tweet_params = if content().length() == 0 {
            "&start_time="+(timestamp_unix()-300).format_timestamp("2006-01-02T15:04:05Z","UTC").escape_url_query()
          } else {
            "&since_id="+content().string()
          }
          meta tweet_search_url = $url_base + $query_base + $tweet_params
          root = ""

  # Hits the Twitter API using the metadata field `tweet_search_url` as the
  # request URL. Tweets in the response are expanded into individual messages,
  # and if at least one tweet is returned then the last tweet ID is cached for
  # the next request.
  - label: search_tweets
    try:
      - resource: next_tweet_search_url

      - label: search_tweets_request
        http:
          url: ${! meta("tweet_search_url") }
          verb: GET
          oauth2:
            enabled: true
            token_url: https://api.twitter.com/oauth2/token
            client_key: "${TWITTER_KEY}"
            client_secret: "${TWITTER_SECRET}"

      - bloblang: root = if (this.data | []).length() > 0 { this.data } else { deleted() }

      - unarchive:
          format: json_array

      - cache:
          # Only bother caching the latest tweet ID (last of the batch).
          parts: [ -1 ]
          resource: request_tracking
          operator: set
          key: last_tweet_id
          value: ${! json("id") }

  # Hits the Twitter search API and for each tweet returned we hit a Discord
  # webhook in order to post the tweet.
  - label: tweets_to_discord
    try:
    - resource: search_tweets

    - bloblang: 'root.content = "https://twitter.com/%v/status/%v".format(this.author_id, this.id)'

    - label: discord_webhook_request
      http:
        parallel: true
        url: "${DISCORD_WEBHOOK_URL}?wait=true"
        verb: POST
        headers:
          Content-Type: application/json

metrics:
  prometheus:
    prefix: ""
    path_mapping: |
      # Undo wonky '_' to '__' replace that's done automatically.
      let path = this.replace("__", "_")
      root = if [
        "search_tweets_request",
        "discord_webhook_request",
      ].any(allowed -> $path.has_prefix(allowed)) { $path } else { deleted() }
